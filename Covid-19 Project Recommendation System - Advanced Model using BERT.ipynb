{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/vidhushinisrinivasan/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/vidhushinisrinivasan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from langdetect import detect\n",
    "import string\n",
    "import emoji\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import mlflow\n",
    "from mlflow import pyfunc\n",
    "import requests\n",
    "import boto3\n",
    "import json\n",
    "import nltk\n",
    "from nltk import word_tokenize \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Import Dataset</H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "raw_github_data = pd.read_csv('data.tsv', sep='\\t', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>github_repo_url</th>\n",
       "      <th>repo_description</th>\n",
       "      <th>topics</th>\n",
       "      <th>owner_repo_name</th>\n",
       "      <th>owner_name</th>\n",
       "      <th>owner_type</th>\n",
       "      <th>organization_bio</th>\n",
       "      <th>repo_created_day</th>\n",
       "      <th>primary_language_name</th>\n",
       "      <th>license_name</th>\n",
       "      <th>...</th>\n",
       "      <th>count_of_stars</th>\n",
       "      <th>count_of_watchers</th>\n",
       "      <th>count_distinct_contributors</th>\n",
       "      <th>count_contributions</th>\n",
       "      <th>count_commits</th>\n",
       "      <th>count_commit_comments</th>\n",
       "      <th>count_created_issues</th>\n",
       "      <th>count_pull_requests_created</th>\n",
       "      <th>count_pull_requests_reviews</th>\n",
       "      <th>count_comments_on_issues_and_pull_requests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://github.com/CSSEGISandData/COVID-19</td>\n",
       "      <td>novel coronavirus (covid-19) cases, provided b...</td>\n",
       "      <td>systems-science, covid-19, johns-hopkins-unive...</td>\n",
       "      <td>CSSEGISandData/COVID-19</td>\n",
       "      <td>CSSEGISandData</td>\n",
       "      <td>User</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-02-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>19434</td>\n",
       "      <td>19417</td>\n",
       "      <td>2746</td>\n",
       "      <td>11609</td>\n",
       "      <td>3256</td>\n",
       "      <td>152</td>\n",
       "      <td>1669</td>\n",
       "      <td>361</td>\n",
       "      <td>119</td>\n",
       "      <td>6052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://github.com/phildini/stayinghomeclub</td>\n",
       "      <td>a list of all the companies wfh or events chan...</td>\n",
       "      <td>remote-work, covid19, covid-19, static-site</td>\n",
       "      <td>phildini/stayinghomeclub</td>\n",
       "      <td>phildini</td>\n",
       "      <td>User</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-03-04</td>\n",
       "      <td>Ruby</td>\n",
       "      <td>cc0-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>456</td>\n",
       "      <td>453</td>\n",
       "      <td>1091</td>\n",
       "      <td>4156</td>\n",
       "      <td>1293</td>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>1350</td>\n",
       "      <td>934</td>\n",
       "      <td>498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://github.com/tokyo-metropolitan-gov/covid19</td>\n",
       "      <td>Êù±‰∫¨ÈÉΩ Êñ∞Âûã„Ç≥„É≠„Éä„Ç¶„Ç§„É´„ÇπÊÑüÊüìÁóáÂØæÁ≠ñ„Çµ„Ç§„Éà / tokyo covid-19 task fo...</td>\n",
       "      <td>covid-19</td>\n",
       "      <td>tokyo-metropolitan-gov/covid19</td>\n",
       "      <td>tokyo-metropolitan-gov</td>\n",
       "      <td>Organization</td>\n",
       "      <td>tokyo metropolitan government</td>\n",
       "      <td>2020-02-29</td>\n",
       "      <td>Vue</td>\n",
       "      <td>mit</td>\n",
       "      <td>...</td>\n",
       "      <td>5174</td>\n",
       "      <td>5165</td>\n",
       "      <td>537</td>\n",
       "      <td>11855</td>\n",
       "      <td>2774</td>\n",
       "      <td>2</td>\n",
       "      <td>906</td>\n",
       "      <td>1473</td>\n",
       "      <td>1533</td>\n",
       "      <td>5167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://github.com/covid19india/covid19india-r...</td>\n",
       "      <td>üìä source code of the main website</td>\n",
       "      <td>covid19-india, tracker, visualization, covid19...</td>\n",
       "      <td>covid19india/covid19india-react</td>\n",
       "      <td>covid19india</td>\n",
       "      <td>Organization</td>\n",
       "      <td>covid19-india ops</td>\n",
       "      <td>2020-03-15</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>mit</td>\n",
       "      <td>...</td>\n",
       "      <td>1676</td>\n",
       "      <td>1673</td>\n",
       "      <td>536</td>\n",
       "      <td>3029</td>\n",
       "      <td>348</td>\n",
       "      <td>6</td>\n",
       "      <td>424</td>\n",
       "      <td>316</td>\n",
       "      <td>167</td>\n",
       "      <td>1768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://github.com/pcm-dpc/COVID-19</td>\n",
       "      <td>covid-19 italia - monitoraggio situazione</td>\n",
       "      <td>covid-19</td>\n",
       "      <td>pcm-dpc/COVID-19</td>\n",
       "      <td>pcm-dpc</td>\n",
       "      <td>Organization</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-03-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>3072</td>\n",
       "      <td>3069</td>\n",
       "      <td>525</td>\n",
       "      <td>2197</td>\n",
       "      <td>171</td>\n",
       "      <td>10</td>\n",
       "      <td>451</td>\n",
       "      <td>49</td>\n",
       "      <td>42</td>\n",
       "      <td>1474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     github_repo_url  \\\n",
       "0         https://github.com/CSSEGISandData/COVID-19   \n",
       "1        https://github.com/phildini/stayinghomeclub   \n",
       "2  https://github.com/tokyo-metropolitan-gov/covid19   \n",
       "3  https://github.com/covid19india/covid19india-r...   \n",
       "4                https://github.com/pcm-dpc/COVID-19   \n",
       "\n",
       "                                    repo_description  \\\n",
       "0  novel coronavirus (covid-19) cases, provided b...   \n",
       "1  a list of all the companies wfh or events chan...   \n",
       "2  Êù±‰∫¨ÈÉΩ Êñ∞Âûã„Ç≥„É≠„Éä„Ç¶„Ç§„É´„ÇπÊÑüÊüìÁóáÂØæÁ≠ñ„Çµ„Ç§„Éà / tokyo covid-19 task fo...   \n",
       "3                  üìä source code of the main website   \n",
       "4          covid-19 italia - monitoraggio situazione   \n",
       "\n",
       "                                              topics  \\\n",
       "0  systems-science, covid-19, johns-hopkins-unive...   \n",
       "1        remote-work, covid19, covid-19, static-site   \n",
       "2                                           covid-19   \n",
       "3  covid19-india, tracker, visualization, covid19...   \n",
       "4                                           covid-19   \n",
       "\n",
       "                   owner_repo_name              owner_name    owner_type  \\\n",
       "0          CSSEGISandData/COVID-19          CSSEGISandData          User   \n",
       "1         phildini/stayinghomeclub                phildini          User   \n",
       "2   tokyo-metropolitan-gov/covid19  tokyo-metropolitan-gov  Organization   \n",
       "3  covid19india/covid19india-react            covid19india  Organization   \n",
       "4                 pcm-dpc/COVID-19                 pcm-dpc  Organization   \n",
       "\n",
       "                organization_bio repo_created_day primary_language_name  \\\n",
       "0                            NaN       2020-02-04                   NaN   \n",
       "1                            NaN       2020-03-04                  Ruby   \n",
       "2  tokyo metropolitan government       2020-02-29                   Vue   \n",
       "3              covid19-india ops       2020-03-15            JavaScript   \n",
       "4                            NaN       2020-03-07                   NaN   \n",
       "\n",
       "  license_name  ...  count_of_stars  count_of_watchers  \\\n",
       "0          NaN  ...           19434              19417   \n",
       "1      cc0-1.0  ...             456                453   \n",
       "2          mit  ...            5174               5165   \n",
       "3          mit  ...            1676               1673   \n",
       "4       other   ...            3072               3069   \n",
       "\n",
       "   count_distinct_contributors  count_contributions  count_commits  \\\n",
       "0                         2746                11609           3256   \n",
       "1                         1091                 4156           1293   \n",
       "2                          537                11855           2774   \n",
       "3                          536                 3029            348   \n",
       "4                          525                 2197            171   \n",
       "\n",
       "   count_commit_comments  count_created_issues  count_pull_requests_created  \\\n",
       "0                    152                  1669                          361   \n",
       "1                      3                    78                         1350   \n",
       "2                      2                   906                         1473   \n",
       "3                      6                   424                          316   \n",
       "4                     10                   451                           49   \n",
       "\n",
       "   count_pull_requests_reviews  count_comments_on_issues_and_pull_requests  \n",
       "0                          119                                        6052  \n",
       "1                          934                                         498  \n",
       "2                         1533                                        5167  \n",
       "3                          167                                        1768  \n",
       "4                           42                                        1474  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_github_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Clean Data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_github_data_filtered = raw_github_data[(raw_github_data['has_merged_prs'] == True) &\n",
    "    (raw_github_data['has_readme'] == True) &\n",
    "    (pd.isna(raw_github_data['repo_description']) == False) &\n",
    "    (pd.isna(raw_github_data['primary_language_name']) == False) &\n",
    "    (raw_github_data['count_distinct_contributors'] >=2)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Correlation Map</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.matshow(raw_github_data_filtered.corr())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Helper Functions </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect language with error handling\n",
    "def detect_with_error_handle(x):\n",
    "    try:\n",
    "        return detect(x)\n",
    "    except:\n",
    "        return 'Error'\n",
    "    \n",
    "# Check for only latin characters\n",
    "def has_only_latin_letters(text):\n",
    "    char_set = string.printable + '‚Äî'\n",
    "    return all((True if x in char_set else False for x in text))\n",
    "\n",
    "# Remove punctuation\n",
    "def remove_punctuation(text):\n",
    "    punctuation_list = string.punctuation + '‚Äî'\n",
    "    return text.translate(str.maketrans('', '', punctuation_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Text Processing</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-449ceb6bdf75>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  raw_github_data_filtered['language'] = raw_github_data_filtered['repo_description'].apply(lambda x: 'None' if pd.isna(x) else detect_with_error_handle(str(x)))\n"
     ]
    }
   ],
   "source": [
    "# check language, limit to english, and limit repo's with latin characters. Emojis are converted in the process\n",
    "raw_github_data_filtered['language'] = raw_github_data_filtered['repo_description'].apply(lambda x: 'None' if pd.isna(x) else detect_with_error_handle(str(x)))\n",
    "raw_github_data_filtered = raw_github_data_filtered[raw_github_data_filtered['language'] == 'en'].copy()\n",
    "raw_github_data_filtered['is_latin_only_characters'] = raw_github_data_filtered['repo_description'].apply(lambda x: has_only_latin_letters(emoji.demojize(x)))\n",
    "raw_github_data_filtered = raw_github_data_filtered[raw_github_data_filtered['is_latin_only_characters'] == True].copy()\n",
    "\n",
    "# clean up repo description, topic, and language, combine into one big bag o' words\n",
    "raw_github_data_filtered['repo_description_cleaned'] = raw_github_data_filtered['repo_description'].apply(lambda x: remove_punctuation(x))\n",
    "raw_github_data_filtered['topics'] = raw_github_data_filtered.apply(lambda x: remove_punctuation(str(x['topics']).replace(',','').replace('nan','')), axis=1)\n",
    "raw_github_data_filtered['topics'].fillna('', inplace=True)\n",
    "raw_github_data_filtered['description_plus_topics'] = raw_github_data_filtered['repo_description_cleaned']+' '+raw_github_data_filtered['topics']+' '+raw_github_data_filtered['primary_language_name']\n",
    "raw_github_data_filtered.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# create repo-lookup object for later use\n",
    "repo_lookup = raw_github_data_filtered.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Tokenizer </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# Create class to be used by tokenizer to lemmatize... which change matches words to their roots\n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, articles):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(articles)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Create Bert Embeddings for Input Data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.24G/1.24G [03:02<00:00, 6.82MB/s] \n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embedder = SentenceTransformer('bert-large-nli-stsb-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1458: DeprecationWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "corpus_embeddings_cleaned = embedder.encode(raw_github_data_filtered['description_plus_topics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.08335491, -0.273391  , -0.84478736, ...,  0.15537384,\n",
       "        -0.02338627,  0.44419217],\n",
       "       [-0.5071723 ,  0.00229374, -0.06180557, ...,  0.64270353,\n",
       "         0.03400471,  1.3523257 ],\n",
       "       [ 0.22075853,  0.47256142, -0.10161404, ...,  0.8410261 ,\n",
       "         0.24130097,  1.0043257 ],\n",
       "       ...,\n",
       "       [ 0.5820951 , -0.6507479 ,  0.66174006, ..., -0.09759206,\n",
       "         0.7494296 , -1.4188712 ],\n",
       "       [-0.2891289 ,  0.32989588, -0.4120548 , ...,  0.7233281 ,\n",
       "         0.10993961,  1.1797737 ],\n",
       "       [-0.20110777, -0.12553403, -0.44665238, ...,  0.45139942,\n",
       "        -0.18576165,  0.7206653 ]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_embeddings_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Build Predicter </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_recommender(input_df, embedder=embedder,  corpus_embeddings_cleaned = corpus_embeddings_cleaned, repo_lookup=repo_lookup):\n",
    "    \n",
    "    input_df['bag_of_words'] = input_df.apply(lambda x: ' '.join(x), axis = 1)\n",
    "    \n",
    "    # vectorize the inputted string\n",
    "    #inputted_vector = word_vectorizer.transform(pd.Series(str(input_string)))\n",
    "    inputted_vector = embedder.encode(input_df['bag_of_words'])\n",
    "    \n",
    "    # calculate cosine similarity with existing matrix\n",
    "    one_dimension_cosine_sim = cosine_similarity(inputted_vector, corpus_embeddings_cleaned)\n",
    "\n",
    "    # creating a Series with the similarity scores in descending order\n",
    "    score_series = pd.Series(one_dimension_cosine_sim[0]).sort_values(ascending = False)\n",
    "    # only show matches that have some similarity\n",
    "    score_series = score_series[score_series>0]\n",
    "\n",
    "    # getting the indexes of the 10 most similar repos\n",
    "    top_10_indexes = list(score_series.iloc[1:11].index)\n",
    "    \n",
    "    # initializing the empty list of recommended repo\n",
    "    \n",
    "    recommended_repos = repo_lookup.loc[top_10_indexes]\n",
    "        \n",
    "    return recommended_repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class covid19RepoReco(pyfunc.PythonModel):   \n",
    "    ## defining objects needed for leadsModel prediction. \n",
    "    def __init__(self,\n",
    "                 embedder,\n",
    "                 corpus_embeddings_cleaned,\n",
    "                 repo_lookup,\n",
    "                 text_recommender):\n",
    "        \n",
    "        ## Setting up all needed objects\n",
    "        self.embedder = embedder\n",
    "        self.corpus_embeddings_cleaned = corpus_embeddings_cleaned\n",
    "        self.repo_lookup = repo_lookup\n",
    "        self.text_recommender = text_recommender\n",
    "    \n",
    "    ## define function with processing and feeding data into prediction at the end\n",
    "    def predict(self,context,model_input):\n",
    "        output_df = self.text_recommender(model_input)\n",
    "        return [output_df.to_dict('records')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Test</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'github_repo_url': 'https://github.com/jeffreysilver/stopcovid-lambdas', 'repo_description': 'www.stopcovid.co', 'topics': '', 'owner_repo_name': 'jeffreysilver/stopcovid-lambdas', 'owner_name': 'jeffreysilver', 'owner_type': 'User', 'organization_bio': nan, 'repo_created_day': '2020-03-18', 'primary_language_name': 'Python', 'license_name': nan, 'is_github_pages': False, 'has_readme': True, 'has_wiki': True, 'has_merged_prs': True, 'has_issues': True, 'has_contributor_guide': False, 'has_code_of_conduct': False, 'count_of_public_forks': 0, 'count_of_stars': 0, 'count_of_watchers': 0, 'count_distinct_contributors': 3, 'count_contributions': 727, 'count_commits': 470, 'count_commit_comments': 0, 'count_created_issues': 0, 'count_pull_requests_created': 87, 'count_pull_requests_reviews': 156, 'count_comments_on_issues_and_pull_requests': 14, 'language': 'en', 'is_latin_only_characters': True, 'repo_description_cleaned': 'wwwstopcovidco', 'description_plus_topics': 'wwwstopcovidco  Python'}, {'github_repo_url': 'https://github.com/covid19db/fetchers-python', 'repo_description': 'data source fetchers written in python', 'topics': '', 'owner_repo_name': 'covid19db/fetchers-python', 'owner_name': 'covid19db', 'owner_type': 'Organization', 'organization_bio': nan, 'repo_created_day': '2020-03-24', 'primary_language_name': 'Python', 'license_name': 'mit', 'is_github_pages': False, 'has_readme': True, 'has_wiki': True, 'has_merged_prs': True, 'has_issues': True, 'has_contributor_guide': False, 'has_code_of_conduct': False, 'count_of_public_forks': 2, 'count_of_stars': 1, 'count_of_watchers': 1, 'count_distinct_contributors': 5, 'count_contributions': 14, 'count_commits': 10, 'count_commit_comments': 0, 'count_created_issues': 0, 'count_pull_requests_created': 2, 'count_pull_requests_reviews': 2, 'count_comments_on_issues_and_pull_requests': 0, 'language': 'en', 'is_latin_only_characters': True, 'repo_description_cleaned': 'data source fetchers written in python', 'description_plus_topics': 'data source fetchers written in python  Python'}, {'github_repo_url': 'https://github.com/SarveshJoshi25/COVID19-DETECTION', 'repo_description': 'relational database management system ', 'topics': '', 'owner_repo_name': 'SarveshJoshi25/COVID19-DETECTION', 'owner_name': 'SarveshJoshi25', 'owner_type': 'User', 'organization_bio': nan, 'repo_created_day': '2020-03-12', 'primary_language_name': 'Python', 'license_name': 'cc0-1.0', 'is_github_pages': False, 'has_readme': True, 'has_wiki': True, 'has_merged_prs': True, 'has_issues': True, 'has_contributor_guide': False, 'has_code_of_conduct': False, 'count_of_public_forks': 2, 'count_of_stars': 1, 'count_of_watchers': 1, 'count_distinct_contributors': 2, 'count_contributions': 86, 'count_commits': 66, 'count_commit_comments': 0, 'count_created_issues': 0, 'count_pull_requests_created': 16, 'count_pull_requests_reviews': 1, 'count_comments_on_issues_and_pull_requests': 3, 'language': 'en', 'is_latin_only_characters': True, 'repo_description_cleaned': 'relational database management system ', 'description_plus_topics': 'relational database management system   Python'}, {'github_repo_url': 'https://github.com/CovidZero/hummingbird', 'repo_description': 'python api of covidzero', 'topics': '', 'owner_repo_name': 'CovidZero/hummingbird', 'owner_name': 'CovidZero', 'owner_type': 'Organization', 'organization_bio': nan, 'repo_created_day': '2020-03-19', 'primary_language_name': 'Python', 'license_name': 'apache-2.0', 'is_github_pages': False, 'has_readme': True, 'has_wiki': True, 'has_merged_prs': True, 'has_issues': True, 'has_contributor_guide': False, 'has_code_of_conduct': False, 'count_of_public_forks': 11, 'count_of_stars': 14, 'count_of_watchers': 14, 'count_distinct_contributors': 9, 'count_contributions': 23, 'count_commits': 8, 'count_commit_comments': 0, 'count_created_issues': 1, 'count_pull_requests_created': 7, 'count_pull_requests_reviews': 5, 'count_comments_on_issues_and_pull_requests': 2, 'language': 'en', 'is_latin_only_characters': True, 'repo_description_cleaned': 'python api of covidzero', 'description_plus_topics': 'python api of covidzero  Python'}, {'github_repo_url': 'https://github.com/civictechhub/crawlers', 'repo_description': 'crawlers to be implemented', 'topics': '', 'owner_repo_name': 'civictechhub/crawlers', 'owner_name': 'civictechhub', 'owner_type': 'Organization', 'organization_bio': \"civictechhub is a hub of civic tech communities and solutions! let's flatten the covid-19 curve together!\", 'repo_created_day': '2020-03-26', 'primary_language_name': 'Python', 'license_name': nan, 'is_github_pages': False, 'has_readme': True, 'has_wiki': True, 'has_merged_prs': True, 'has_issues': True, 'has_contributor_guide': False, 'has_code_of_conduct': False, 'count_of_public_forks': 5, 'count_of_stars': 2, 'count_of_watchers': 2, 'count_distinct_contributors': 6, 'count_contributions': 54, 'count_commits': 25, 'count_commit_comments': 0, 'count_created_issues': 3, 'count_pull_requests_created': 13, 'count_pull_requests_reviews': 6, 'count_comments_on_issues_and_pull_requests': 7, 'language': 'en', 'is_latin_only_characters': True, 'repo_description_cleaned': 'crawlers to be implemented', 'description_plus_topics': 'crawlers to be implemented  Python'}, {'github_repo_url': 'https://github.com/covid-projections/covid-data-public', 'repo_description': 'public source data used by covid-data-model and/or covid-projections', 'topics': '', 'owner_repo_name': 'covid-projections/covid-data-public', 'owner_name': 'covid-projections', 'owner_type': 'Organization', 'organization_bio': nan, 'repo_created_day': '2020-03-26', 'primary_language_name': 'Python', 'license_name': 'mit', 'is_github_pages': False, 'has_readme': True, 'has_wiki': False, 'has_merged_prs': True, 'has_issues': True, 'has_contributor_guide': False, 'has_code_of_conduct': False, 'count_of_public_forks': 4, 'count_of_stars': 5, 'count_of_watchers': 5, 'count_distinct_contributors': 11, 'count_contributions': 155, 'count_commits': 80, 'count_commit_comments': 1, 'count_created_issues': 10, 'count_pull_requests_created': 13, 'count_pull_requests_reviews': 14, 'count_comments_on_issues_and_pull_requests': 37, 'language': 'en', 'is_latin_only_characters': True, 'repo_description_cleaned': 'public source data used by coviddatamodel andor covidprojections', 'description_plus_topics': 'public source data used by coviddatamodel andor covidprojections  Python'}, {'github_repo_url': 'https://github.com/danbilokha/covid19knowledgebase', 'repo_description': 'covid19 knowledgebase', 'topics': '', 'owner_repo_name': 'danbilokha/covid19knowledgebase', 'owner_name': 'danbilokha', 'owner_type': 'User', 'organization_bio': nan, 'repo_created_day': '2020-03-29', 'primary_language_name': 'Python', 'license_name': nan, 'is_github_pages': False, 'has_readme': True, 'has_wiki': True, 'has_merged_prs': True, 'has_issues': True, 'has_contributor_guide': False, 'has_code_of_conduct': False, 'count_of_public_forks': 0, 'count_of_stars': 2, 'count_of_watchers': 2, 'count_distinct_contributors': 3, 'count_contributions': 64, 'count_commits': 49, 'count_commit_comments': 0, 'count_created_issues': 6, 'count_pull_requests_created': 5, 'count_pull_requests_reviews': 0, 'count_comments_on_issues_and_pull_requests': 4, 'language': 'en', 'is_latin_only_characters': True, 'repo_description_cleaned': 'covid19 knowledgebase', 'description_plus_topics': 'covid19 knowledgebase  Python'}, {'github_repo_url': 'https://github.com/codersagainstcovidorg/covid19testing-backend', 'repo_description': 'the backend for findcovidtesting.com', 'topics': '', 'owner_repo_name': 'codersagainstcovidorg/covid19testing-backend', 'owner_name': 'codersagainstcovidorg', 'owner_type': 'Organization', 'organization_bio': nan, 'repo_created_day': '2020-03-23', 'primary_language_name': 'Python', 'license_name': 'gpl-3.0', 'is_github_pages': False, 'has_readme': True, 'has_wiki': True, 'has_merged_prs': True, 'has_issues': True, 'has_contributor_guide': False, 'has_code_of_conduct': False, 'count_of_public_forks': 0, 'count_of_stars': 3, 'count_of_watchers': 3, 'count_distinct_contributors': 2, 'count_contributions': 77, 'count_commits': 59, 'count_commit_comments': 0, 'count_created_issues': 0, 'count_pull_requests_created': 8, 'count_pull_requests_reviews': 7, 'count_comments_on_issues_and_pull_requests': 3, 'language': 'en', 'is_latin_only_characters': True, 'repo_description_cleaned': 'the backend for findcovidtestingcom', 'description_plus_topics': 'the backend for findcovidtestingcom  Python'}, {'github_repo_url': 'https://github.com/paulinawins/CovidProject', 'repo_description': 'covid ct scan detection web application', 'topics': 'javascript python', 'owner_repo_name': 'paulinawins/CovidProject', 'owner_name': 'paulinawins', 'owner_type': 'User', 'organization_bio': nan, 'repo_created_day': '2020-03-26', 'primary_language_name': 'Python', 'license_name': nan, 'is_github_pages': False, 'has_readme': True, 'has_wiki': True, 'has_merged_prs': True, 'has_issues': True, 'has_contributor_guide': False, 'has_code_of_conduct': False, 'count_of_public_forks': 1, 'count_of_stars': 1, 'count_of_watchers': 1, 'count_distinct_contributors': 3, 'count_contributions': 93, 'count_commits': 88, 'count_commit_comments': 0, 'count_created_issues': 0, 'count_pull_requests_created': 5, 'count_pull_requests_reviews': 0, 'count_comments_on_issues_and_pull_requests': 0, 'language': 'en', 'is_latin_only_characters': True, 'repo_description_cleaned': 'covid ct scan detection web application', 'description_plus_topics': 'covid ct scan detection web application javascript python Python'}, {'github_repo_url': 'https://github.com/2kruman/COVID19-NZ-known-cases', 'repo_description': 'dataset of known cases in nz', 'topics': '', 'owner_repo_name': '2kruman/COVID19-NZ-known-cases', 'owner_name': '2kruman', 'owner_type': 'User', 'organization_bio': nan, 'repo_created_day': '2020-03-19', 'primary_language_name': 'Python', 'license_name': nan, 'is_github_pages': False, 'has_readme': True, 'has_wiki': True, 'has_merged_prs': True, 'has_issues': True, 'has_contributor_guide': False, 'has_code_of_conduct': False, 'count_of_public_forks': 1, 'count_of_stars': 2, 'count_of_watchers': 2, 'count_distinct_contributors': 2, 'count_contributions': 131, 'count_commits': 34, 'count_commit_comments': 0, 'count_created_issues': 25, 'count_pull_requests_created': 14, 'count_pull_requests_reviews': 1, 'count_comments_on_issues_and_pull_requests': 57, 'language': 'en', 'is_latin_only_characters': True, 'repo_description_cleaned': 'dataset of known cases in nz', 'description_plus_topics': 'dataset of known cases in nz  Python'}]]\n"
     ]
    }
   ],
   "source": [
    "# Testing the prediction class before pushing to MLflow\n",
    "m = covid19RepoReco(embedder = embedder,\n",
    "                                       corpus_embeddings_cleaned = corpus_embeddings_cleaned,\n",
    "                                       repo_lookup = repo_lookup,\n",
    "                                       text_recommender = text_recommender)\n",
    "model_input = pd.DataFrame([[\"Python\", \"Data\"]])\n",
    "model_output = m.predict(None,model_input)\n",
    "print(model_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Log to MLflow</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# connect to MLflow\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"Covid19RepoRecommender\") # creates an experiment if it doesn't exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_conda_env = {\n",
    " 'name': 'mlflow-env',\n",
    " 'channels': ['defaults',\n",
    "              'conda-forge'],\n",
    " 'dependencies': ['python=3.6.2',\n",
    "                  'nltk=3.4.5',\n",
    "                  'nltk_data',\n",
    "                  {'pip': ['mlflow==1.6.0',\n",
    "                           'scikit-learn',\n",
    "                           'cloudpickle==1.2.2']}\n",
    "                 ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"Covid Repo Recommender\") as run:\n",
    "    mlflow.log_param(\"num_repos_returned\", 10)\n",
    "    \n",
    "    pyfunc.log_model(\n",
    "        artifact_path = \"covid_repo_reco_pyfunc\",\n",
    "        python_model = covid19RepoReco(embedder = embedder,\n",
    "                                       corpus_embeddings_cleaned = corpus_embeddings_cleaned,\n",
    "                                       repo_lookup = repo_lookup,\n",
    "                                       text_recommender = text_recommender),\n",
    "        conda_env = mlflow_conda_env\n",
    "    )\n",
    "    \n",
    "    run_id = run.info.run_uuid\n",
    "    experiment_id = run.info.experiment_id\n",
    "    \n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Test Local Deployment</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlflow sagemaker run-local -m ./mlruns/1/be7ec6c8ff424583b2bad6d9dfd063b0/artifacts/covid_repo_reco_pyfunc -p 5001\n"
     ]
    }
   ],
   "source": [
    "# Run this command in the same directory as MLflow to kick-off a local sagemaker build\n",
    "\n",
    "sagemaker_local_command = 'mlflow sagemaker run-local -m ./mlruns/{experiment_id}/{run_id}/artifacts/covid_repo_reco_pyfunc -p 5001'. \\\n",
    "    format(experiment_id=experiment_id,run_id=run_id)\n",
    "\n",
    "print(sagemaker_local_command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a function to test out the locally-build sagemaker container\n",
    "def query_local_endpoint(input_json):\n",
    "    response = requests.post('http://localhost:5001/invocations'\n",
    "                           , headers = {'Content-Type': 'application/json'} \n",
    "                           , data=input_json)\n",
    "    print(response)\n",
    "    preds = response.json()\n",
    "    return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running a query against the local endpoint and examining the output\n",
    "model_input = pd.DataFrame([[\"Python\", \"Data\"]])\n",
    "output=query_local_endpoint(model_input.to_json(orient=\"split\"))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Deploy to Sagemaker</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If the local sagemaker testing went well, it's time to deploy!\n",
    "\n",
    "## Note: this requires a MLflow pyfunc docker container to already exist in sagemaker\n",
    "\n",
    "import mlflow.sagemaker as mfs\n",
    "\n",
    "\n",
    "# we pull the run and experiment id's from above to create this mlflow location\n",
    "model_uri = \"mlruns/%s/%s/artifacts/covid_repo_reco_pyfunc\" % (experiment_id,run_id)\n",
    "\n",
    "# The region is chosen, pick whats close to you or your systems!\n",
    "region = \"us-east-1\"\n",
    "# The aws account id can be found in the console\n",
    "aws_account_id = \"XXXXXXX\"\n",
    "# We use these inputs to automatically reference the sagemaker docker container\n",
    "image_url = aws_account_id \\\n",
    "            + \".dkr.ecr.\" \\\n",
    "            + region \\\n",
    "            + \".amazonaws.com/mlflow-pyfunc:1.5.0\"\n",
    "\n",
    "# now we specify the role that we setup for sagemaker in the previous step\n",
    "sagemaker_arn = \"arn:aws:iam::XXXXXXX:role/AmazonSageMakerFullAccess\"\n",
    "\n",
    "\n",
    "# finally, we pick a name for our endpoint within sagemaker\n",
    "endpoint_name = \"covid19-repo-rec\" \n",
    "\n",
    "\n",
    "# with all of the inputs, we run the following to deploy the model it sagemaker\n",
    "mfs.deploy(app_name=endpoint_name, \n",
    "           model_uri=model_uri,\n",
    "           region_name=region,\n",
    "           mode=\"create\", #this should change to replace if the endpoint already exists\n",
    "           execution_role_arn=sagemaker_arn,\n",
    "           image_url=image_url, \n",
    "           instance_type='ml.t2.medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
